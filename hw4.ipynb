{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will implement an audio matching system that can recognize a live performance of classical music.\n",
    "\n",
    "I have provided a skeleton of the code below, and you will fill in any sections marked with `### START CODE BLOCK ###` and `### END CODE BLOCK ###`.  Please do not change the code outside of these markers.  In particular, do not define any new functions, change the code decomposition, or modify function inputs, outputs, or default values.  Note that this code is written for ease of understanding and ease of grading, not for efficiency.\n",
    "\n",
    "Once you have completed this assignment, please run all cells in your notebook, make sure that all plots, images, and outputs are embedded in the notebook, and then submit your .ipynb file on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partner 1 Name: Madeleine Kan\n",
    "\n",
    "Number of hours spent (Partner 1): 10\n",
    "\n",
    "Partner 2 Name: Elena Schwartz \n",
    "\n",
    "Number of hours spent (Partner 2): 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb # for reference, my solutions use librosa version 0.7.2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "import glob\n",
    "import os.path\n",
    "import subprocess\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore') # to suppress warning messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Chroma Features (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part you will implement a function that extracts chroma features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the extractChromaFeatures function, you should:\n",
    "- load the audio using librosa.core.load\n",
    "- calculate the STFT using scipy.signal.stft\n",
    "- compute the squared magnitude of STFT coefficients\n",
    "- determine the log frequency conversion matrix by calling getLogFreqConversionMatrix()\n",
    "- determine the chroma conversion matrix by calling getChromaConversionMatrix()\n",
    "- compute chroma features by applying the chroma conversion matrix\n",
    "- apply element-wise logarithmic compression by calling logCompression()\n",
    "- L2 normalize each column by calling normL2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elena\n",
    "def extractChromaFeatures(mp3file, sr = 22050, winsize = 2048, hop = 512, gamma = 10000):\n",
    "    '''\n",
    "    Compute chroma feature matrix on a specified audio file.\n",
    "    \n",
    "    Arguments:\n",
    "    mp3file -- path to mp3 file\n",
    "    sr -- desired sampling rate in Hz\n",
    "    winsize -- analysis window size in samples\n",
    "    hop -- hop size in samples\n",
    "    gamma -- coefficient used in log compression\n",
    "    \n",
    "    Returns:\n",
    "    F -- chroma feature matrix of size (12, M), where M is the number of audio frames.  The\n",
    "         features have logarithmic compression and each column is L2 normalized.\n",
    "    '''\n",
    "    ### START CODE BLOCK ###\n",
    "    Y, sr1  = lb.core.load(mp3file, sr = sr)\n",
    "    f, t, S = stft(Y, fs = sr1, nperseg = winsize, noverlap = winsize - hop)\n",
    "    square = np.square(np.abs(S))\n",
    "    B = getLogFreqConversionMatrix(winsize, sr1)\n",
    "    W = getChromaConversionMatrix(B)\n",
    "    F = np.matmul(W, square)\n",
    "    feat = logCompression(F, gamma = 10000)\n",
    "    F = normL2(feat)\n",
    "\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the log frequency spectrogram Slog, we can simply pre-multiply the one-sided spectrogram S with a matrix B.  If S has dimensions (N/2)+1 rows by M columns, then B will have 128 rows by (N/2)+1 columns.\n",
    "\n",
    "In the getLogFreqConversionMatrix function, you should:\n",
    "- determine the lower and upper bound in Hz for each pitch band for p=0, 1, ..., 127\n",
    "- determine the DFT indices that fall within the lower and upper bounds for each pitch value\n",
    "- set the appropriate indices in B to construct the log frequency conversion matrix\n",
    "\n",
    "Note that B will be a binary matrix containing only zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Madeleine\n",
    "def getLogFreqConversionMatrix(N, fs):\n",
    "    '''\n",
    "    Determine the log frequency conversion matrix that can be used to pre-multiply a one-sided spectrogram\n",
    "    to get a log frequency spectrogram.\n",
    "    \n",
    "    Arguments:\n",
    "    N -- analysis window size\n",
    "    fs -- sampling rate \n",
    "    \n",
    "    Returns:\n",
    "    B -- a binary matrix of shape (128, (N/2)+1).  The log frequency spectrogram can be computed\n",
    "         by computing the matrix product of B and the spectrogram matrix.\n",
    "    '''\n",
    "    numBins = int(N/2) + 1\n",
    "    pitchMax = 128\n",
    "    B = np.zeros((pitchMax, numBins))\n",
    "    p = np.arange(pitchMax)\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    # determine STFT params, construct STFT, multiply STFT by B\n",
    "    # freq from midi number (p):\n",
    "    # f(p) = 440*2^((p-69)/12)\n",
    "    # Set of DFT indices: \n",
    "    # k: f_pitch(p-1/2) <= k*fs/N <= f_pitch(p+1/2)\n",
    "    # # first, construct list of k index ranges: [[kmin0, kmax0], [kmin1, kmax1], ... [kmin127, kmax127]]\n",
    "    \n",
    "    k = np.arange(numBins)\n",
    "\n",
    "    idx_rngs = np.array(pitchMax*[np.zeros(2)])\n",
    "    # for p_i in range(len(freq_rngs)):\n",
    "    for p_i in p:\n",
    "        # multiply freq min and max by N/fs to turn into index \n",
    "        # idx_rngs[p_i][0] = N*440*2**((p_i + 70 - 0.5)/12)/fs # min\n",
    "        # idx_rngs[p_i][1] = N*440*2**((p_i + 70 + 0.5)/12)/fs # max\n",
    "        idx_min = int((N/fs)*440*2**((p_i - 69 - 0.5)/12)) # min\n",
    "        idx_max = int((N/fs)*440*2**((p_i - 69 + 0.5)/12)) # max\n",
    "        B[p_i][idx_min:idx_max] = 1\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELena\n",
    "def getChromaConversionMatrix(B):\n",
    "    '''\n",
    "    Determine the chroma conversion matrix that can be used to pre-multiply a one-sided spectrogram\n",
    "    to calculate chroma features.\n",
    "    \n",
    "    Arguments:\n",
    "    B -- log frequency conversion matrix\n",
    "    \n",
    "    Returns:\n",
    "    W -- a binary matrix with 12 rows and the same number of columns as B.  Chroma features can be computed\n",
    "         as the matrix product of W and the spectrogram matrix.\n",
    "    '''\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    # convert STFT from pitch bands to chroma\n",
    "    # multiply S by W\n",
    "    W = np.zeros((12, B.shape[0]), dtype = int)\n",
    "\n",
    "\n",
    "    for i in range(B.shape[0]):\n",
    "        W[i%12, i] = 1\n",
    "\n",
    "    W = np.matmul(W,B)\n",
    "    W = np.roll(W, 1, axis=1) #jank temporary solution that just shifts everything by 1\n",
    "    \n",
    " \n",
    "    ### END CODE BLOCK ###\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logCompression function, you should:\n",
    "- apply logarithmic compression ln(1 + gamma * c) to each element c.  Note that the log is with base e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Madeleine\n",
    "def logCompression(F, gamma = 10000):\n",
    "    '''\n",
    "    Apply element-wise logarithmic compression.\n",
    "    \n",
    "    Arguments:\n",
    "    F -- input matrix\n",
    "    gamma -- scalar that controls the level of compression as ln(1 + gamma * c)\n",
    "    \n",
    "    Returns:\n",
    "    Fc -- matrix of logarithmically compressed values.  Fc is of the same size as F.\n",
    "    '''\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    # via https://www.geeksforgeeks.org/python/how-to-map-a-function-over-numpy-array/\n",
    "    # https://stackoverflow.com/questions/10593100/how-do-you-do-natural-logs-e-g-ln-with-numpy-in-python\n",
    "    logscale = np.vectorize(lambda x: np.log(1+gamma*x))\n",
    "    Fc = logscale(F)\n",
    "    # multiply eahc element of matrix F by logarithmic scale\n",
    "    ### START CODE BLOCK ###\n",
    "\n",
    "    return Fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the normL2 function, you should:\n",
    "- normalize each column of a matrix to have unit L2 norm\n",
    "\n",
    "Make sure to implement this in a vectorized way.  Also, you will want to add a small epsilon (e.g. `1e-9`) to the denominator in case you have a column of all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elena\n",
    "def normL2(F):\n",
    "    '''\n",
    "    Normalize each column of a matrix to have unit L2 norm.\n",
    "    \n",
    "    Arguments:\n",
    "    F -- input feature matrix where each column corresponds to a single feature vector\n",
    "    \n",
    "    Returns:\n",
    "    Fnorm -- normalized feature matrix of the same shape as F, where each column has been\n",
    "             been normalized to be unit L2 norm\n",
    "    '''\n",
    "    # take each row and calculate dot product with itself to normalize \n",
    "    \n",
    "    # originally tried this, but it applied elementwise instead of rowwise\n",
    "    # normalizeCol = np.vectorize(lambda col: (col/np.sqrt(np.dot(col, col))))\n",
    "    normalizeCol = lambda col: (col/np.sqrt(np.dot(col, col)))\n",
    "    # along axis 0 means function is applied to each column!\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.apply_along_axis.html\n",
    "    Fnorm = np.apply_along_axis(normalizeCol, axis=0, arr=F)\n",
    "\n",
    "    return Fnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17571658 -1.20929252  0.36040965 -0.22163588 -0.11497629  0.98389737\n",
      "   0.2874768  -0.64221492 -0.57168736  0.47163047]\n",
      " [ 1.33106954 -0.29457574  1.31193884  1.45723635 -0.20229916  1.38351968\n",
      "   0.50787944  1.88695615  0.02926418  0.71487731]\n",
      " [ 0.59271336 -1.30794007 -1.3385336  -0.01980898  0.02196296  0.13725218\n",
      "   0.18460744  0.98694508 -0.39778815 -0.67065226]\n",
      " [-1.59374993  0.75494183 -0.66326264  0.67494033 -0.01936539  2.53029518\n",
      "   0.97407488 -0.91877953 -1.68594915 -1.30722165]\n",
      " [-0.89179219 -2.61177846 -1.68114069 -2.01425523 -0.54636914 -0.06191376\n",
      "  -1.01388586  1.24819449 -0.88403747  1.12485081]]\n",
      "[[ 2.17571658  0.79070748  2.36040965  1.77836412  1.88502371  2.98389737\n",
      "   2.2874768   1.35778508  1.42831264  2.47163047]\n",
      " [ 3.33106954  1.70542426  3.31193884  3.45723635  1.79770084  3.38351968\n",
      "   2.50787944  3.88695615  2.02926418  2.71487731]\n",
      " [ 2.59271336  0.69205993  0.6614664   1.98019102  2.02196296  2.13725218\n",
      "   2.18460744  2.98694508  1.60221185  1.32934774]\n",
      " [ 0.40625007  2.75494183  1.33673736  2.67494033  1.98063461  4.53029518\n",
      "   2.97407488  1.08122047  0.31405085  0.69277835]\n",
      " [ 1.10820781 -0.61177846  0.31885931 -0.01425523  1.45363086  1.93808624\n",
      "   0.98611414  3.24819449  1.11596253  3.12485081]]\n",
      "[[ 2.17571658  3.33106954  2.59271336  0.40625007  1.10820781]\n",
      " [ 0.79070748  1.70542426  0.69205993  2.75494183 -0.61177846]\n",
      " [ 2.36040965  3.31193884  0.6614664   1.33673736  0.31885931]\n",
      " [ 1.77836412  3.45723635  1.98019102  2.67494033 -0.01425523]\n",
      " [ 1.88502371  1.79770084  2.02196296  1.98063461  1.45363086]\n",
      " [ 2.98389737  3.38351968  2.13725218  4.53029518  1.93808624]\n",
      " [ 2.2874768   2.50787944  2.18460744  2.97407488  0.98611414]\n",
      " [ 1.35778508  3.88695615  2.98694508  1.08122047  3.24819449]\n",
      " [ 1.42831264  2.02926418  1.60221185  0.31405085  1.11596253]\n",
      " [ 2.47163047  2.71487731  1.32934774  0.69277835  3.12485081]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5,10)\n",
    "print(a)\n",
    "add2 = np.vectorize(lambda col: col + 2)\n",
    "print(add2(a))\n",
    "print(add2(np.transpose(a)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some sample outputs to use for debugging and verifying that your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = getLogFreqConversionMatrix(2048, 22050)\n",
    "B[64,25:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = getChromaConversionMatrix(B)\n",
    "C[0,0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  9.21044037,  9.90353755],\n",
       "       [10.30898599, 10.59665973, 10.81979828],\n",
       "       [11.00211651, 11.15626481, 11.28979441]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logCompression(np.arange(9).reshape((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[ 0.        ,  9.21044037,  9.90353755],\n",
    "       [10.30898599, 10.59665973, 10.81979828],\n",
    "       [11.00211651, 11.15626481, 11.28979441]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = normL2(np.random.randn(5,10))\n",
    "np.sum(T * T, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F = extractChromaFeatures('queries/chopin_alternate_query.mp3') #changed this file because i couldn't find chopin1-2.mp3 in queries\n",
    "plt.imshow(F[:,0:50], cmap = 'jet', origin = 'lower')\n",
    "plt.show() # I can't see the actualy picture so not sure if this is right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sampleChromaFeats.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Database (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will construct the database of features.\n",
    "\n",
    "In the constructDB function, you should:\n",
    "- create a python dictionary that will contain the database\n",
    "- iterate through the mp3 files in the specified directory using glob.glob\n",
    "- extract chroma features from each file\n",
    "- store the chroma feature matrix in the dictionary, where the dictionary key is a string specifying the piece name and the value is a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Madeleine\n",
    "def constructDB(indir):\n",
    "    '''\n",
    "    Constructs a database containing the feature matrices for all reference tracks.\n",
    "    \n",
    "    Arguments:\n",
    "    indir -- directory containing the mp3 files to store in the database\n",
    "    \n",
    "    Returns:\n",
    "    db -- a dictionary where the key is the name of the piece and the value is its chroma feature matrix\n",
    "    '''\n",
    "    db = {}\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    dir = f\"{indir}/*\"\n",
    "    filepaths = glob.glob(dir)\n",
    "\n",
    "    for path in filepaths:\n",
    "        # https://stackoverflow.com/questions/7336096/python-glob-without-the-whole-path-only-the-filename\n",
    "        songname = os.path.basename(path)\n",
    "        chroma_feature_matrix = extractChromaFeatures(path) # sr = 22050, winsize = 2048, hop = 512, gamma = 10000\n",
    "        db[songname] = chroma_feature_matrix\n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the constructDB function and save the database to file using `pickle.dump` for later use.  Note that this may take about a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach.mp3': 0,\n",
       " 'beethoven.mp3': 0,\n",
       " 'chopin.mp3': 0,\n",
       " 'debussy.mp3': 0,\n",
       " 'liszt.mp3': 0,\n",
       " 'rach.mp3': 0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = constructDB(\"references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.pkl','wb') as f:\n",
    "    pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.pkl','rb') as f:\n",
    "    db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsequence DTW (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will implement functions necessary to run subsequence DTW.  The tasks you must complete are:\n",
    "- implement the computeCostMatrix_costdist function\n",
    "- implement the subsequenceDTW function\n",
    "- compare the output of your function to librosa.core.dtw to verify that they match on a single example\n",
    "- plot the cost matrix and overlay the predicted alignment path for a single example\n",
    "- listen to the query and predicted matching segment of the reference to verify that the alignment was done correctly\n",
    "- calculate the ratio between the query audio length and the matching segment length\n",
    "\n",
    "Please make sure to include all work in your notebook to get full credit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the computeCostMatrix_cosdist function, you should:\n",
    "- compute the cosine distance cost matrix C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Madeleine\n",
    "def computeCostMatrix_cosdist(Fquery,Fref):\n",
    "    '''\n",
    "    Computes the cosine distance cost matrix.\n",
    "    \n",
    "    Arguments:\n",
    "    Fquery -- the query chroma feature matrix of dimension (12, # query frames), this feature\n",
    "              matrix is assumed to be L2 normalized\n",
    "    Fref -- the reference feature matrix, of dimension (12, # reference frames), this feature\n",
    "            matrix is assumed to be L2 normalized\n",
    "    \n",
    "    Returns:\n",
    "    C -- cost matrix whose (i,j)th element specifies the cosine distance between the i-th query frame\n",
    "         and the j-th reference frame\n",
    "    '''\n",
    "    # C(i, j) = 1 - (transposed ith col of Fref)*(jth col of Fquery)\n",
    "    # in matrix form, becomes C = (matrix of 1s) - ( Fquery_transpose * Fref)\n",
    "    Mr = len(Fref)\n",
    "    Mq = len(Fquery)\n",
    "    ones = np.ones(Mq, Mr)\n",
    "    FqueryT = np.transpose(Fquery)\n",
    "    cos_dist_matrix = np.matmul(FqueryT, Fref)\n",
    "    C = ones - cos_dist_matrix\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequenceDTW function, you should:\n",
    "- initialize the cumulative cost matrix D and backtrace matrix B\n",
    "- compute the values in D and B using dynamic programming\n",
    "- call the `backtrace` function to determine the optimal path\n",
    "- construct the optimal subsequence path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elena\n",
    "def subsequenceDTW(C, steps, weights):\n",
    "    '''\n",
    "    Find the optimal subsequence path through cost matrix C.\n",
    "    \n",
    "    Arguments:\n",
    "    C -- cost matrix of dimension (# query frames, # reference frames)\n",
    "    steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    weights -- a vector of size L specifying the multiplicative weights associated \n",
    "                with each of the allowable transitions\n",
    "                \n",
    "    Returns:\n",
    "    optcost -- the optimal subsequence path score\n",
    "    path -- a matrix with 2 columns specifying the optimal subsequence path.  Each row \n",
    "            specifies the (row, col) coordinate.\n",
    "    '''\n",
    "    D = np.zeros(C.shape)\n",
    "    B = np.zeros(C.shape, dtype=np.int8)\n",
    "\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "\n",
    "    # Start with  i = Mq, j = Mr\n",
    "    # stepAboveCost, pathAbove = D[i-1, j] + C[i, j]*w1\n",
    "    # stepleftCost, pathLeft = \"\"\"\"\n",
    "    # stepdiagonalCost, pathDiagnola = \"\"\"\"\n",
    "    # costOptions = [aboveCost, leftCost, diagCost]\n",
    "    # bestCost = min(costOptions)\n",
    "    #  bestPath = pathOptions[costOptions.index(bestCost)]\n",
    "    # optCost = optcost + bestCost\n",
    "    # path = path + bestpath\n",
    "    # TODO: how to initialize cost and path without resetting it? does it need to be an input\n",
    "    # TODO: will this work within reasonable time\n",
    "    \n",
    "    costOptions = []\n",
    "\n",
    "    for i in range(len(C.shape[0])): # iterate through all rows\n",
    "        for j in range(len(C[i,:])): # iterate through all columns\n",
    "             for k in range(len(steps)): # check that all steps are possible \n",
    "                 if i - steps[k][0] >= 0 and j - steps[k][1] >= 0: \n",
    "                        # if step in bounds add cost option for step\n",
    "                        costOptions.append([D[i-steps[k][0],j-steps[k][1]] + C[i,j]*weights[k]])\n",
    "                 else:\n",
    "                      # if not in bounds add infinity so that step is not choosen\n",
    "                      costOptions.append(np.inf)\n",
    "                      \n",
    "             D[i,j] = min(costOptions) # find minimum of cost options \n",
    "             B[i,j] = steps[costOptions.index(D[i,j])] # appending step it took to get best cost\n",
    "\n",
    "\n",
    "    path = backtrace(D, B, steps)\n",
    "    optcost = D[path[0][0]-1, path[0][1]-1] \n",
    "             \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    path = np.array(path)\n",
    "    \n",
    "    return optcost, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the backtrace function, you should:\n",
    "- determine the coordinate of the ending point on the optimal path\n",
    "- follow the backtrace pointers and append each coordinate to `path`\n",
    "- return a list of the coordinates in the optimal subsequence path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elena\n",
    "def backtrace(D, B, steps):\n",
    "    '''\n",
    "    Backtraces through the cumulative cost matrix D.\n",
    "    \n",
    "    Arguments:\n",
    "    D -- cumulative cost matrix\n",
    "    B -- backtrace matrix\n",
    "    steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    \n",
    "    Returns:\n",
    "    path -- a python list of (row, col) coordinates for the optimal path.\n",
    "    '''\n",
    "\n",
    "    path = []\n",
    "    # start at i, j, subtract B(i,j), save that coordinate in path, go to that new coordinate, rinse and repeat\n",
    "    ### START CODE BLOCK ###\n",
    "    path.append((0,B[0].index(min(B[0])))) \n",
    "\n",
    "    while \n",
    "        path.append(path[0][0]+B[path[0][0]], path[0][1]+B[path])\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if your implementation is correct, verify that your function's output matches the output of librosa.core.dtw on the following example (please do not change the parameters below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryfile = 'queries/beethoven_alternate_query.mp3'\n",
    "reffile = 'references/beethoven.mp3'\n",
    "steps = np.array([2, 1, 1, 2, 1, 1]).reshape((3,2))\n",
    "weights = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fquery = extractChromaFeatures(queryfile)\n",
    "Fref = extractChromaFeatures(reffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '12' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m D, wp = lb.sequence.dtw(C=\u001b[43mcomputeCostMatrix_cosdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFref\u001b[49m\u001b[43m)\u001b[49m, step_sizes_sigma=steps, weights_mul=weights, subseq=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m wp[-\u001b[32m5\u001b[39m:], np.min(D[-\u001b[32m1\u001b[39m,:])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcomputeCostMatrix_cosdist\u001b[39m\u001b[34m(Fquery, Fref)\u001b[39m\n\u001b[32m     18\u001b[39m Mr = \u001b[38;5;28mlen\u001b[39m(Fref)\n\u001b[32m     19\u001b[39m Mq = \u001b[38;5;28mlen\u001b[39m(Fquery)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m ones = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m FqueryT = np.transpose(Fquery)\n\u001b[32m     22\u001b[39m cos_dist_matrix = np.matmul(FqueryT, Fref)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/E207_Spr26/lib/python3.13/site-packages/numpy/_core/numeric.py:233\u001b[39m, in \u001b[36mones\u001b[39m\u001b[34m(shape, dtype, order, device, like)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ones_with_like(\n\u001b[32m    230\u001b[39m         like, shape, dtype=dtype, order=order, device=device\n\u001b[32m    231\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m a = \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m multiarray.copyto(a, \u001b[32m1\u001b[39m, casting=\u001b[33m'\u001b[39m\u001b[33munsafe\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mTypeError\u001b[39m: Cannot interpret '12' as a data type"
     ]
    }
   ],
   "source": [
    "D, wp = lb.sequence.dtw(C=computeCostMatrix_cosdist(Fquery, Fref), step_sizes_sigma=steps, weights_mul=weights, subseq=True)\n",
    "wp[-5:], np.min(D[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your own implementation of subsequence DTW and verify that the outputs match\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cost matrix as an image and overlay the predicted alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the query and the predicted matching segment of the reference.  You can use IPython.display.Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to query\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to matching segment of reference\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the ratio of the query length to the matching segment length.  This gives an overall sense of how similar or different the tempos are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will put all the pieces together to implement an audio matching system and measure its accuracy.  You must do the following:\n",
    "- implement runBenchmark function\n",
    "- run the benchmark and display the accuracy of your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the runBenchmark function, you should:\n",
    "- iterate through the query files in the specified directory\n",
    "- extract features on the query\n",
    "- compute the match score of each piece in the database using subsequence DTW\n",
    "- check if the predicted piece is correct\n",
    "\n",
    "To speed up your experiment, you may use `lb.sequence.dtw` in place of your own subsequenceDTW implementation.  You should compute the cost matrix using your `computeCostMatrix_cosdist` function, and then pass the cost matrix to `lb.sequence.dtw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Madeleine\n",
    "def runBenchmark(d, indir, steps, weights, shorten = None):\n",
    "    '''\n",
    "    Runs a benchmark on a given set of queries and returns the accuracy of the system.\n",
    "    \n",
    "    Arguments:\n",
    "    d -- database of chroma feature matrices\n",
    "    indir -- directory containing query mp3 files\n",
    "    steps -- matrix specifying allowable transitions in the subsequence DTW, size (L, 2)\n",
    "    weights -- vector of length L specifying the multiplicative weights of each transition\n",
    "    shorten -- a float between 0 and 1 specifying what fraction of the query to use.  For example, \n",
    "               when shorten = .5, only the first 50% of the features will be used.\n",
    "               \n",
    "    Returns:\n",
    "    accuracy -- the fraction of queries that were identified correctly\n",
    "    '''\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    querypaths = glob.glob(f\"{indir}/*\")\n",
    "    \n",
    "\n",
    "    for path in range(len(querypaths)):\n",
    "        songname = os.path.basename(path)\n",
    "        Fquery = extractChromaFeatures(path) # sr = 22050, winsize = 2048, hop = 512, gamma = 10000\n",
    "        C = computeCostMatrix_cosdist(Fquery, Fref)\n",
    "        optcost, path = lb.sequence.DTW(C, steps, weights)\n",
    "        # make dictionary of songs and costs\n",
    "        db[songname] = chroma_feature_matrix\n",
    "    # optimal guess is song with lowest cost\n",
    "    # check if it's what we expect\n",
    "    # update accuracy\n",
    "    # maybe write best guess func?\n",
    "\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "\n",
    "    matches = 0\n",
    "\n",
    "    for attempt in range(len(query_songpaths_list)):\n",
    "        query_file = query_songpaths_list[attempt]\n",
    "        query_songid = query_songids_list[attempt]\n",
    "        bestMatch = findBestMatch(query_file, db, ref_dir, verbose = False)\n",
    "        if (query_songid == bestMatch):\n",
    "            matches += 1\n",
    "        elif verbose:\n",
    "            print(f\"query song id: {query_songid}, (incorrect) best guess: {bestMatch}\")\n",
    "        attempt += 1\n",
    "\n",
    "    accuracy = matches/attempt\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the benchmark and print out the system accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will run additional experiments to gain more intuition about how subsequence DTW works.  You should do the following:\n",
    "- Run a set of experiments that varies two different parameters: the length of the audio query and the DTW transition weights.  The allowable transitions should be fixed to {(1,1), (1,2), (2,1)}.\n",
    "- Create a plot that shows how accuracy changes for the following query lengths: 3 sec, 2 sec, 1 sec, .75 sec, .5 sec, .25 sec.  Your plot should also compare the following two weighting schemes: `{1,1,1}` and `{1,1,2}`.  This will require you to run your benchmark 12 times with different settings.\n",
    "- Describe which weighting scheme is better for very short queries and provide an intuitive explanation for why that weighting scheme should be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run series of benchmarks\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot of results\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E207_Spr26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
